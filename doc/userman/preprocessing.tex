\chapter{Preprocessing}

This section describes the implementation of the C++ preprocessor for \acslpp
annotations. Recall that thte C++ preprocessor replaces comments (including
\acslpp comments) by white space, without operations such as handling
preprocessor directives. Accordingly, \fclang must handle standard
preprocessing within \acslpp annotations itself.

As a refresher, the C/C++ preprocessor (CPP) (cf. \url{https://gcc.gnu.org/onlinedocs/cpp/}) conceptually implements the following operations on a C++ source file:
\begin{itemize}
	\item The input is read and broken it into a sequence of physical lines according to the line terminators (ASCII character sequences \texttt{\\r}, \texttt{\\n}, or \texttt{\\r\\n}).
	\item Each C trigraph is replaced by its corresponding character.
	\item Any backslash-whitespace-line-terminator sequence is removed and the line that it ends is combined with the following line.
	\item Comments are replaced by single spaces. This requires tokenizing the input to avoid recognizing comment markers within strings as indicating a comment. Note that this allows block comments to hide line terminations.
	\item The input text is divided into preprocessing tokens grouped in logical lines. Each preprocessor token becomes a compiler token (except where \#\# concatenation occurs). However, \acslb tokens are slightly different, as described below.
	\item The source text is transformed according to any preprocessing directives contained within it. Each preprocessing directive must be contained within one logical line
    \item adjacent string literals (separatedonly by white-space or line-endings) are concatenated into a single string literal.
	
\end{itemize}
The result is a sequence of preprocessing tokens that is passed on to the 
remaining compiler phases.

\subsection{Trigraphs}

TBD - are these supported by clang?

\subsection{Digraphs}
Digraphs are alternate spellings of preprocessort tokens, in particular, of
punctuation character sequences. No digraphs are defined in \acslpp for use
in \acslpp annotations.

\subsection{Preprocessor tokens}
Preprocessor tokens (per CPP) belong to one of five categories. White space (space, tab) serves only to separate tokens; it is not needed between tokens whose concatenation is not a single token. Line terminators also separate tokens and also delineate certain features: preprocessing directives and string literals do not extend over more than one (logical) line.
\begin{itemize}
	\item identifiers: character sequences that match the regular expression \\
\centerline{\texttt{[a-zA-Z\_][a-zA-Z\_0-9]*}} .\\ Dollar signs are allowed as non-digit identifier characters if the clang option \texttt{-fdollars-in-identifiers} is used. (TBD - on by default?)
	\item number: character sequences that match the regular expression  \\
\centerline{\texttt{[.]?[0-9]([0-9a-zA-Z.]|[eEpP][+-]))*}} . \\
(TBD - dollar signs also allowed?)
	\item string literals: character sequence enclosed in " " or ' ' or < >, with \textbackslash " for " in a double-quoted literal (that is not a header file name) and \' for ' in a single-quoted literal.
	\item punctuator: all single non-alphanumeric printable characters except 
\verb|@|, \verb|#| and \verb|`|, and all multi-punctuation sequences that meaningful to C/C++ (e.g. > and >{>}= ), but not an arbitrary multi-punctuation character sequence.
	\item other tokens: \verb|@|, \verb|#|, \verb|`| and all non-ASCII single characters.
\end{itemize}
The above token definitions imply that arbitrary text can always be broken into
legitimate tokens, with the exception of a few characters and of badly formed unicode sequences.

TODO - unicode characters

Note that not all preprocessor tokens are valid C/C++ parser tokens. Tokens in the other category have no meaning to C/C++ and the \texttt{number} category allows many sequences that are not legal C/C++ numeric tokens. These tokens will generally provoke compiler errors. For example in C/C++, 0..2 is one token and is not interpreted as two consecutive numeric tokens.

\acsl and \acslpp have slightly different tokens than the above, so the preprocessor tokens need to be re-tokenized in some cases:
\begin{itemize}
	\item The \verb|@| token is a whitespace character in \acslb.
	\item There are some \acslb multi-character punctuator tokens that are not
	single preprocessor tokens:
	\begin{itemize}
        \item[] all \acslb keywords that begin with a backslash, such as
         \verb|\result|.
		\item[] $==>$ (logical implies)
		\item[] $-->$ (bit-wise implies)
		\item[] $<==>$ (logical equality)
		\item[] $<-->$ (bit-wise equality)
		\item[] \verb|^^| (logical inequality)
		\item[] \verb|^*| (list repetition)
		\item[] \verb:[|: and \verb:|]: (list creation)
	\end{itemize}
	These \acslb tokens need to be assembled from multiple CPP tokens (and those CPP tokens must not be separated by white space)
	\item A CPP numeric token that contains .. will not be a legal C/C++ number, but may be a sequence of
 legal \acslb tokens with the .. representing the range operator.  For example, the single CPP token \texttt{0..last} is retokenized for \acslb as if it were written \texttt{0 .. last} .
	\item \acslb allows certain built-in non-ASCII symbols.
    An example is 
		$\forall$ (unicode 0x2200) x to designate a universal quantifier,
    which is an alternative form of \verb|\forall|.
    A complete list of such tokens is given  in the \acslb language definition.
\end{itemize}

\subsection{Preprocessor directives}
A preprocessing directive consists of a single logical line (after the previous preprocessing phases have been completed) that begins with optional white space, the '\#' character, additional optional white space, and a preprocessor directive identifier.
The preprocessing language contains a fixed set of preprocessing directive identifiers:
\begin{itemize}
	\item \texttt{define}, \texttt{undef}
	\item \texttt{if}, \texttt{ifdef}, \texttt{ifndef}, \texttt{elif}, \texttt{else}, \texttt{endif}
	\item \texttt{warning}, \texttt{error}
	\item \texttt{include}
	\item \texttt{line}
	\item \texttt{pragma}
\end{itemize}
In addition, identifiers that have been defined (by a \#define directive) as macros are expanded according to the macro expansion rules (not described here).

Now \acslb annotations are contained in C/C++ comments. 
Consequently, any directives contained in the annotation are not seen when the source file is processed simply as a C/C++ source file. However, the effect of some directives lasts until the end of the source file. 
Accordingly, \acslpp imposes constraints on the directives that may be present within annotations:
\begin{itemize}
	\item \texttt{define} and \texttt{undef} are not permitted in an annotation
	\item \texttt{if}, \texttt{ifdef}, \texttt{ifndef}, \texttt{elif}, \texttt{else}, \texttt{endif} are permitted but must be completely nested within the annotation in which they appear (an \texttt{endif} and its corresponding \texttt{if/ifdef/ifndef} must be in the same annotation comment.)
	\item \texttt{warning} and \texttt{error} are permitted
	\item \texttt{include} is permitted, but will cause errors if it contains, as is almost always the case, either \texttt{define} or \texttt{pragma} directives
	\item \texttt{line} - TBD
	\item \texttt{pragma} is not permitted
\end{itemize}

